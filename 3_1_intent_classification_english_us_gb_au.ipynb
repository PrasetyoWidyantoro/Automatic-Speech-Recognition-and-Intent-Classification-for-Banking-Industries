{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "id": "TZ2wa39AMnT3"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:00:58.177840Z",
     "iopub.status.busy": "2024-07-26T00:00:58.177562Z",
     "iopub.status.idle": "2024-07-26T00:01:44.217795Z",
     "shell.execute_reply": "2024-07-26T00:01:44.216640Z",
     "shell.execute_reply.started": "2024-07-26T00:00:58.177814Z"
    },
    "id": "ourbRCr7MnT5",
    "outputId": "07c8c192-67ad-4153-ec8b-b76d10b20372"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.2)\n",
      "Collecting pip\n",
      "  Downloading pip-24.1.2-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.1.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.2\n",
      "    Uninstalling pip-23.3.2:\n",
      "      Successfully uninstalled pip-23.3.2\n",
      "Successfully installed pip-24.1.2\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.43.2-py3-none-any.whl.metadata (43 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m792.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.32.1)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.33.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting jiwer\n",
      "  Downloading jiwer-3.0.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: tensorboard in /opt/conda/lib/python3.10/site-packages (2.15.1)\n",
      "Collecting tensorboard\n",
      "  Downloading tensorboard-2.17.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: datasets[audio] in /opt/conda/lib/python3.10/site-packages (2.20.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets[audio]) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.23.4)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (6.0.1)\n",
      "Requirement already satisfied: soundfile>=0.12.1 in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.12.1)\n",
      "Requirement already satisfied: librosa in /opt/conda/lib/python3.10/site-packages (from datasets[audio]) (0.10.2.post1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.3 in /opt/conda/lib/python3.10/site-packages (from jiwer) (8.1.7)\n",
      "Collecting rapidfuzz<4,>=3 (from jiwer)\n",
      "  Downloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.60.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.5.2)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.20.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (69.0.3)\n",
      "Requirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard) (3.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets[audio]) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets[audio]) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets[audio]) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets[audio]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets[audio]) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets[audio]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets[audio]) (2024.7.4)\n",
      "Requirement already satisfied: cffi>=1.0 in /opt/conda/lib/python3.10/site-packages (from soundfile>=0.12.1->datasets[audio]) (1.16.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
      "Requirement already satisfied: audioread>=2.1.9 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (3.0.1)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.2.2)\n",
      "Requirement already satisfied: joblib>=0.14 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.4.2)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (5.1.1)\n",
      "Requirement already satisfied: numba>=0.51.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.58.1)\n",
      "Requirement already satisfied: pooch>=1.1 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.8.2)\n",
      "Requirement already satisfied: soxr>=0.3.2 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.3.7)\n",
      "Requirement already satisfied: lazy-loader>=0.1 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (0.3)\n",
      "Requirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.10/site-packages (from librosa->datasets[audio]) (1.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets[audio]) (2023.4)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.0->soundfile>=0.12.1->datasets[audio]) (2.21)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba>=0.51.0->librosa->datasets[audio]) (0.41.1)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from pooch>=1.1->librosa->datasets[audio]) (3.11.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20.0->librosa->datasets[audio]) (3.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading transformers-4.43.2-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading accelerate-0.33.0-py3-none-any.whl (315 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.1/315.1 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jiwer-3.0.4-py3-none-any.whl (21 kB)\n",
      "Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading rapidfuzz-3.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m75.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, tensorboard, jiwer, accelerate, transformers, evaluate\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.15.1\n",
      "    Uninstalling tensorboard-2.15.1:\n",
      "      Successfully uninstalled tensorboard-2.15.1\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.32.1\n",
      "    Uninstalling accelerate-0.32.1:\n",
      "      Successfully uninstalled accelerate-0.32.1\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.42.3\n",
      "    Uninstalling transformers-4.42.3:\n",
      "      Successfully uninstalled transformers-4.42.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\n",
      "tensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\n",
      "tensorflow 2.15.0 requires tensorboard<2.16,>=2.15, but you have tensorboard 2.17.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed accelerate-0.33.0 evaluate-0.4.2 jiwer-3.0.4 rapidfuzz-3.9.4 tensorboard-2.17.0 transformers-4.43.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade datasets[audio] transformers accelerate evaluate jiwer tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:23:54.832762Z",
     "iopub.status.busy": "2024-07-26T00:23:54.832354Z",
     "iopub.status.idle": "2024-07-26T00:24:08.773528Z",
     "shell.execute_reply": "2024-07-26T00:24:08.772352Z",
     "shell.execute_reply.started": "2024-07-26T00:23:54.832734Z"
    },
    "id": "ETRZRB_DMnT6",
    "outputId": "9bb16105-e770-4a20-dc99-43de7645146f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.20.0)\n",
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.5.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:01:44.220590Z",
     "iopub.status.busy": "2024-07-26T00:01:44.220089Z",
     "iopub.status.idle": "2024-07-26T00:01:47.322500Z",
     "shell.execute_reply": "2024-07-26T00:01:47.321728Z",
     "shell.execute_reply.started": "2024-07-26T00:01:44.220549Z"
    },
    "id": "NXYaGQiYMnT6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from datasets import load_from_disk\n",
    "import soundfile as sf\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:20:28.791927Z",
     "iopub.status.busy": "2024-07-26T00:20:28.791518Z",
     "iopub.status.idle": "2024-07-26T00:20:28.796341Z",
     "shell.execute_reply": "2024-07-26T00:20:28.795257Z",
     "shell.execute_reply.started": "2024-07-26T00:20:28.791899Z"
    },
    "id": "WZRuiq6TMnT6"
   },
   "outputs": [],
   "source": [
    "from datasets import DatasetDict, Dataset, Audio\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:20:40.923730Z",
     "iopub.status.busy": "2024-07-26T00:20:40.923080Z",
     "iopub.status.idle": "2024-07-26T00:20:44.428305Z",
     "shell.execute_reply": "2024-07-26T00:20:44.427370Z",
     "shell.execute_reply.started": "2024-07-26T00:20:40.923698Z"
    },
    "id": "FamjmVLvMnT6",
    "outputId": "14e14290-b834-4954-f259-e5322c650a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['audio', 'intent_class'],\n",
      "        num_rows: 1085\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['audio', 'intent_class'],\n",
      "        num_rows: 362\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['audio', 'intent_class'],\n",
      "        num_rows: 362\n",
      "    })\n",
      "})\n",
      "{'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/28aa727f91fee90575c34956bab09d1716cfaf460c6afcba86a10f04a7d58b83/en-AU~JOINT_ACCOUNT/CA2eba5c350b1958b865a28507ffd11abf_2.wav', 'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00024414,\n",
      "       -0.00024414, -0.00024414]), 'sampling_rate': 8000}, 'intent_class': 11}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets, DatasetDict\n",
    "\n",
    "# Load datasets for all selected languages\n",
    "lang_used = [\"en-US\", \"en-GB\", \"en-AU\"]\n",
    "minds = []\n",
    "for lang in lang_used:\n",
    "    minds_data = load_dataset(\"PolyAI/minds14\", name=lang, trust_remote_code=True)\n",
    "    minds.append(minds_data['train'])\n",
    "\n",
    "# Concatenate all datasets\n",
    "minds = concatenate_datasets(minds)\n",
    "\n",
    "# Split the concatenated dataset into train and test sets\n",
    "minds = minds.train_test_split(test_size=0.4, seed=21, stratify_by_column=\"intent_class\")\n",
    "\n",
    "# Further split the test set into test and validation sets\n",
    "minds_test = minds['test'].train_test_split(test_size=0.5, seed=21, stratify_by_column=\"intent_class\")\n",
    "\n",
    "# Create a DatasetDict with train, test, and valid splits\n",
    "dataset = DatasetDict({\n",
    "    'train': minds['train'],\n",
    "    'test': minds_test['test'],\n",
    "    'valid': minds_test['train']\n",
    "})\n",
    "\n",
    "# Remove unnecessary columns\n",
    "dataset = dataset.remove_columns([\"path\", \"transcription\", \"english_transcription\", \"lang_id\"])\n",
    "\n",
    "# Inspect the structure of the dataset\n",
    "print(dataset)\n",
    "\n",
    "# Print a sample from the train set to verify the structure\n",
    "print(dataset[\"train\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:22:41.869180Z",
     "iopub.status.busy": "2024-07-26T00:22:41.868765Z",
     "iopub.status.idle": "2024-07-26T00:22:41.875064Z",
     "shell.execute_reply": "2024-07-26T00:22:41.874175Z",
     "shell.execute_reply.started": "2024-07-26T00:22:41.869151Z"
    },
    "id": "TSI34yj7MnT7"
   },
   "outputs": [],
   "source": [
    "labels = minds[\"train\"].features[\"intent_class\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:22:43.802798Z",
     "iopub.status.busy": "2024-07-26T00:22:43.802151Z",
     "iopub.status.idle": "2024-07-26T00:22:43.808378Z",
     "shell.execute_reply": "2024-07-26T00:22:43.807471Z",
     "shell.execute_reply.started": "2024-07-26T00:22:43.802764Z"
    },
    "id": "ZhVw9KaNMnT7",
    "outputId": "3a59b36b-a910-4279-8aec-1b7d91a782a3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'app_error'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2label[str(2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "a123799f79bc4fb58e92963d2c7f9289",
      "afa8345befcf476e99693f5be317a8a0"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T00:22:47.091024Z",
     "iopub.status.busy": "2024-07-26T00:22:47.090678Z",
     "iopub.status.idle": "2024-07-26T00:22:51.855402Z",
     "shell.execute_reply": "2024-07-26T00:22:51.854522Z",
     "shell.execute_reply.started": "2024-07-26T00:22:47.090997Z"
    },
    "id": "669-74GUMnT7",
    "outputId": "b77f2656-6e92-49fa-8d00-03fc258516e5"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a123799f79bc4fb58e92963d2c7f9289",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/159 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afa8345befcf476e99693f5be317a8a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor\n",
    "\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(\"facebook/wav2vec2-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:22:51.858418Z",
     "iopub.status.busy": "2024-07-26T00:22:51.857153Z",
     "iopub.status.idle": "2024-07-26T00:22:51.887638Z",
     "shell.execute_reply": "2024-07-26T00:22:51.886757Z",
     "shell.execute_reply.started": "2024-07-26T00:22:51.858378Z"
    },
    "id": "myDtznywMnT7",
    "outputId": "13817174-3dec-4657-a8d4-bea805af7623"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '/root/.cache/huggingface/datasets/downloads/extracted/28aa727f91fee90575c34956bab09d1716cfaf460c6afcba86a10f04a7d58b83/en-AU~JOINT_ACCOUNT/CA2eba5c350b1958b865a28507ffd11abf_2.wav',\n",
       " 'audio': {'path': '/root/.cache/huggingface/datasets/downloads/extracted/28aa727f91fee90575c34956bab09d1716cfaf460c6afcba86a10f04a7d58b83/en-AU~JOINT_ACCOUNT/CA2eba5c350b1958b865a28507ffd11abf_2.wav',\n",
       "  'array': array([ 0.        ,  0.        ,  0.        , ..., -0.00028209,\n",
       "         -0.00025095, -0.00011901]),\n",
       "  'sampling_rate': 16000},\n",
       " 'transcription': 'hey ID like to set up a bank account for myself and my partner',\n",
       " 'english_transcription': 'hey ID like to set up a bank account for myself and my partner',\n",
       " 'intent_class': 11,\n",
       " 'lang_id': 2}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minds = minds.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "minds[\"train\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:23:05.740478Z",
     "iopub.status.busy": "2024-07-26T00:23:05.739758Z",
     "iopub.status.idle": "2024-07-26T00:23:05.745570Z",
     "shell.execute_reply": "2024-07-26T00:23:05.744406Z",
     "shell.execute_reply.started": "2024-07-26T00:23:05.740447Z"
    },
    "id": "gDdm15usMnT8"
   },
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    audio_arrays = [x[\"array\"] for x in examples[\"audio\"]]\n",
    "    inputs = feature_extractor(\n",
    "        audio_arrays, sampling_rate=feature_extractor.sampling_rate, max_length=16000, truncation=True\n",
    "    )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "b870f485fc0f4890a0b3ae78dd02b808",
      "c0c4791a8f604c449dfec484a9fd581c"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T00:23:06.731270Z",
     "iopub.status.busy": "2024-07-26T00:23:06.730594Z",
     "iopub.status.idle": "2024-07-26T00:23:23.941021Z",
     "shell.execute_reply": "2024-07-26T00:23:23.940252Z",
     "shell.execute_reply.started": "2024-07-26T00:23:06.731240Z"
    },
    "id": "hi8YF6zxMnT8",
    "outputId": "03e63f6d-d87c-4bb2-c35f-62afdd5283f2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b870f485fc0f4890a0b3ae78dd02b808",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1085 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-26 00:23:11.733012: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-26 00:23:11.733142: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-26 00:23:11.865796: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c4791a8f604c449dfec484a9fd581c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/724 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_minds = minds.map(preprocess_function, remove_columns=\"audio\", batched=True)\n",
    "encoded_minds = encoded_minds.rename_column(\"intent_class\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "c8668fcd4cc8411a95ae96a876be82fa"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T00:24:20.131293Z",
     "iopub.status.busy": "2024-07-26T00:24:20.130907Z",
     "iopub.status.idle": "2024-07-26T00:24:22.142984Z",
     "shell.execute_reply": "2024-07-26T00:24:22.142058Z",
     "shell.execute_reply.started": "2024-07-26T00:24:20.131260Z"
    },
    "id": "y1JIJQsgMnT8",
    "outputId": "af7a4e6f-f42e-413e-8b1d-5597d4511133"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8668fcd4cc8411a95ae96a876be82fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import evaluate\n",
    "\n",
    "accuracy = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:24:26.772101Z",
     "iopub.status.busy": "2024-07-26T00:24:26.771737Z",
     "iopub.status.idle": "2024-07-26T00:24:26.777017Z",
     "shell.execute_reply": "2024-07-26T00:24:26.776067Z",
     "shell.execute_reply.started": "2024-07-26T00:24:26.772074Z"
    },
    "id": "jZaPY6a7MnT8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions = np.argmax(eval_pred.predictions, axis=1)\n",
    "    return accuracy.compute(predictions=predictions, references=eval_pred.label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "01f8e20401204103a4cf174bab4709f9"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-07-26T00:24:27.462643Z",
     "iopub.status.busy": "2024-07-26T00:24:27.462251Z",
     "iopub.status.idle": "2024-07-26T00:24:30.304509Z",
     "shell.execute_reply": "2024-07-26T00:24:30.303726Z",
     "shell.execute_reply.started": "2024-07-26T00:24:27.462613Z"
    },
    "id": "LDs6njqPMnT8",
    "outputId": "936e61d9-d1f4-4ad7-f939-9520642d67bf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/configuration_utils.py:364: UserWarning: Passing `gradient_checkpointing` to a config initialization is deprecated and will be removed in v5 Transformers. Using `model.gradient_checkpointing_enable()` instead, or if you are using the `Trainer` API, pass `gradient_checkpointing=True` in your `TrainingArguments`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01f8e20401204103a4cf174bab4709f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/380M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of Wav2Vec2ForSequenceClassification were not initialized from the model checkpoint at facebook/wav2vec2-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'projector.bias', 'projector.weight', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForAudioClassification, TrainingArguments, Trainer\n",
    "\n",
    "num_labels = len(id2label)\n",
    "model = AutoModelForAudioClassification.from_pretrained(\n",
    "    \"facebook/wav2vec2-base\", num_labels=num_labels, label2id=label2id, id2label=id2label\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:24:32.101109Z",
     "iopub.status.busy": "2024-07-26T00:24:32.100752Z",
     "iopub.status.idle": "2024-07-26T00:24:32.183418Z",
     "shell.execute_reply": "2024-07-26T00:24:32.182638Z",
     "shell.execute_reply.started": "2024-07-26T00:24:32.101081Z"
    },
    "id": "nN2XMTcoMnT8"
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"audio_classification_mind_model\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    gradient_accumulation_steps=1,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=4,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,  # Set this to False to avoid pushing to Hugging Face Hub\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:24:35.194367Z",
     "iopub.status.busy": "2024-07-26T00:24:35.193999Z",
     "iopub.status.idle": "2024-07-26T00:24:36.070961Z",
     "shell.execute_reply": "2024-07-26T00:24:36.070190Z",
     "shell.execute_reply.started": "2024-07-26T00:24:35.194339Z"
    },
    "id": "D3Q8qDevMnT8"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_minds[\"train\"],\n",
    "    eval_dataset=encoded_minds[\"test\"],\n",
    "    tokenizer=feature_extractor,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-26T00:24:36.073275Z",
     "iopub.status.busy": "2024-07-26T00:24:36.072638Z",
     "iopub.status.idle": "2024-07-26T00:27:35.084547Z",
     "shell.execute_reply": "2024-07-26T00:27:35.083635Z",
     "shell.execute_reply.started": "2024-07-26T00:24:36.073241Z"
    },
    "id": "gkEAPRYbMnT9",
    "outputId": "12baeff9-839a-46bf-b220-65d78f6bca25"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240726_002448-w7sh297h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/widyantoro-uin-syarif-hidayatullah-jakarta/huggingface/runs/w7sh297h' target=\"_blank\">audio_classification_mind_model</a></strong> to <a href='https://wandb.ai/widyantoro-uin-syarif-hidayatullah-jakarta/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/widyantoro-uin-syarif-hidayatullah-jakarta/huggingface' target=\"_blank\">https://wandb.ai/widyantoro-uin-syarif-hidayatullah-jakarta/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/widyantoro-uin-syarif-hidayatullah-jakarta/huggingface/runs/w7sh297h' target=\"_blank\">https://wandb.ai/widyantoro-uin-syarif-hidayatullah-jakarta/huggingface/runs/w7sh297h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='272' max='272' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [272/272 02:26, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.649000</td>\n",
       "      <td>2.640619</td>\n",
       "      <td>0.075967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.648900</td>\n",
       "      <td>2.638849</td>\n",
       "      <td>0.074586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.645900</td>\n",
       "      <td>2.638456</td>\n",
       "      <td>0.071823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.638800</td>\n",
       "      <td>2.638258</td>\n",
       "      <td>0.074586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=272, training_loss=2.6432824169888214, metrics={'train_runtime': 178.451, 'train_samples_per_second': 24.32, 'train_steps_per_second': 1.524, 'total_flos': 3.940255057536e+16, 'train_loss': 2.6432824169888214, 'epoch': 4.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QbmF68AvMnT9"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J0g3UR6_MnT9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
